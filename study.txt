sp_unique
KDTree
self.label和self.tree的关系:self.tree是一个字典，key是不同的event(y),value储存着所有可能的vector
self.label同样是字典，有相同的key, value也是一个字典，key是self.tree的index，value则是对应vector的score。
当相同的vector有不同的score时，取最大值。
对每一个event都做一个KDTree
从相同的y里面找attention相近的？对找到最近的就从self.label对应的event和index赋值。
是根据vector进行dbscan的吗？
vectorize函数把所有的event sequence按attention的值加起来
一个event sequence就是一个长度300的vector，vector的每一个位置不是0就是对应事件的attention value。vectors把不到confidence的sequence去掉
训练流程：
先把context builder 训练完成
再训练interpreter



step:
1. intepreter的输出
2. check the accuracy for the context builder.




    precision    recall  f1-score   support

           0     0.2906    0.7973    0.4260       370
           1     0.0000    0.0000    0.0000        14
           2     0.0000    0.0000    0.0000         7
           3     0.0000    0.0000    0.0000       117
           4     0.0000    0.0000    0.0000         3
           5     0.0000    0.0000    0.0000         9
           6     0.0000    0.0000    0.0000         1
           7     0.0000    0.0000    0.0000         1
           9     0.0000    0.0000    0.0000        61
          10     0.0000    0.0000    0.0000       207
          11     0.0000    0.0000    0.0000        14
          12     0.1341    0.0542    0.0772       203
          13     0.0000    0.0000    0.0000         3
          14     0.0000    0.0000    0.0000         9
          16     0.0000    0.0000    0.0000        32
          18     0.0000    0.0000    0.0000         1
          19     0.0000    0.0000    0.0000         2
          21     0.0000    0.0000    0.0000       134
          22     0.0000    0.0000    0.0000         5
          23     0.0000    0.0000    0.0000         7
          24     0.1538    0.5000    0.2353         4
          25     0.0000    0.0000    0.0000         0
          26     0.5942    0.5517    0.5722       812
          27     0.5455    0.6090    0.5755       798
          29     0.0000    0.0000    0.0000         5
          30     0.0000    0.0000    0.0000         1
          31     0.0000    0.0000    0.0000         2
          32     0.0000    0.0000    0.0000         5
          33     0.0000    0.0000    0.0000        12
          36     0.0000    0.0000    0.0000        69
          37     0.0000    0.0000    0.0000         4
          38     0.0000    0.0000    0.0000         1
          39     0.0000    0.0000    0.0000         2
          40     0.0000    0.0000    0.0000         3
          41     0.0000    0.0000    0.0000         1
          42     0.0000    0.0000    0.0000         1
          43     0.0000    0.0000    0.0000         1
          44     0.0000    0.0000    0.0000         2
          45     0.9783    0.9231    0.9499       195
          46     0.0000    0.0000    0.0000         2
          47     0.0000    0.0000    0.0000        13
          49     1.0000    0.6667    0.8000        21
          50     1.0000    0.8205    0.9014        39
          51     0.9091    0.9091    0.9091        11
          52     0.0000    0.0000    0.0000         3
          53     0.0000    0.0000    0.0000         6
          54     0.0000    0.0000    0.0000         0
          55     0.0000    0.0000    0.0000         2
          56     0.9753    0.9186    0.9461        86
          57     0.7632    0.7073    0.7342        41
          58     0.0000    0.0000    0.0000         2
          59     0.0000    0.0000    0.0000        24
          60     0.0000    0.0000    0.0000         1
          61     0.2249    0.9691    0.3650       194
          62     0.0000    0.0000    0.0000         2
          63     0.0000    0.0000    0.0000         1
          64     0.0000    0.0000    0.0000         6
          65     0.0000    0.0000    0.0000         2
          66     0.0000    0.0000    0.0000        16
          67     0.0000    0.0000    0.0000         4
          68     0.0000    0.0000    0.0000         4
          69     0.0000    0.0000    0.0000         4
          70     0.0000    0.0000    0.0000         1
          72     0.0000    0.0000    0.0000         3
          73     0.0000    0.0000    0.0000         4
          74     0.0000    0.0000    0.0000        36
          75     0.9165    0.9145    0.9155       924
          76     0.0000    0.0000    0.0000         1
          78     0.0000    0.0000    0.0000       146
          79     0.0000    0.0000    0.0000        71
          80     0.0000    0.0000    0.0000         2
          81     0.0000    0.0000    0.0000         1
          82     0.0000    0.0000    0.0000         4
          84     0.0000    0.0000    0.0000         3
          85     0.0000    0.0000    0.0000        42
          86     0.0000    0.0000    0.0000         3
          87     0.0000    0.0000    0.0000         3
          89     1.0000    0.7857    0.8800        28
          90     0.0000    0.0000    0.0000        26
          91     0.0000    0.0000    0.0000         3
          92     0.0000    0.0000    0.0000         1
          93     0.0000    0.0000    0.0000         1
          94     0.0000    0.0000    0.0000         4
          95     0.0000    0.0000    0.0000         2
          96     0.0000    0.0000    0.0000         1
          97     0.0000    0.0000    0.0000         2
          98     0.0000    0.0000    0.0000         1
          99     0.0000    0.0000    0.0000        10
         100     0.0000    0.0000    0.0000        10
         101     0.0000    0.0000    0.0000         3
         102     0.0000    0.0000    0.0000         0
         103     0.0000    0.0000    0.0000         4
         104     0.0000    0.0000    0.0000         5
         105     0.0000    0.0000    0.0000         7
         106     0.0000    0.0000    0.0000         1
         107     0.0000    0.0000    0.0000         1
         108     0.0000    0.0000    0.0000         1
         112     0.0000    0.0000    0.0000         3

    accuracy                         0.5325      4960
   macro avg     0.0968    0.1033    0.0948      4960
weighted avg     0.4733    0.5325    0.4835      4960

 the result using deepcase to the dataset:
 be cautious about event 61, 78
 用全部的数据集训练context builder,用浓缩数据集训练deeocase？